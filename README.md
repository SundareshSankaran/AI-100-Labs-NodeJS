# AI-100 Hands-on materials

## Lab files for AI100T01A ILT Course

Content is currently being validated and refreshed as of Aug 2019.

## Lab 1: Introducing Azure Cognitive Services

In this lab, we will introduce our case study and setup tools on your local workstation and in your Azure instance to enable you to build tools within the Microsoft Cognitive Services suite.

- [case study](/Lab01/01-Introduction_Case_Study.md)
- [set up](/Lab01/README.md)

### Time to complete: 60 min

## Lab 2: Implement Computer Vision

This hands-on lab guides you through creating an intelligent console application from end-to-end using Cognitive Services (specifically the Computer Vision API). We use the ImageProcessing portable class library (PCL), discussing its contents and how to use it in your own applications.

- [hands-on](/Lab02/README.md)

### Time to complete: 60 min


## Lab 3: Creating a Basic Filtering Bot

In this lab, we will be setting up an intelligent bot from end-to-end that can respond to a user's chat window text prompt. We will be building on what we have already learned about building bots within Azure, but adding in a layer of custom logic to give our bot more bespoke functionality.

**cumming soon**

### Time to complete: 90 min


## Lab 4: Implement Logging for Bot

In the previous lab, we built a chat bot and modified the downloaded code to suit out needs. Now, we wish to log bot chats to enable our customer service team to follow up to inquiries, determine if the bot is performing in the expected manner, and to analyze customer data.

**cumming soon**

### Time to complete: 30 min


## Lab 5: Integrate QnA Maker with a Bot

QnA Maker provides a conversational question and answer layer over your data. This allows your bot to send QnA Maker a question and receive an answer without you needing to parse and interpret the intent of their question.

**cumming soon**

### Time to complete: 30 min


## Lab 6: Implement the LUIS Model

We're going to build an end-to-end scenario that allows you to pull in your own pictures, use Cognitive Services to find objects and people in the images, and obtain a description and tags. We'll later build a Bot Framework bot using LUIS to allow easy, targeted querying.

**cumming soon**

### Time to complete: 45 min


## Lab 7: Integrate LUIS into Bot Dialogs

In this hands-on our bot will be capable of taking in a user's input and responding based on the user's input, we will give our bot the ability to understand natural language with the LUIS model we built in previous exercise.

**cumming soon**

### Time to complete: 45 min

## Lab 8: Language Detection and Translation in a Bot

In this hands-on we implement Language Detection feature of the Azure Text Analytics REST API evaluates text input for each document and returns language identifiers with a score that indicates the strength of the analysis. The Language Detection feature can detect a wide range of languages, variants, dialects, and some regional or cultural languages. The exact list of languages for this feature isn't published. Those capabilities will be added to the bot developed before.

**cumming soon**

### Time to complete: 45 min

## Lab 9: Connect to Bots in DirectLine 

This hands-on lab guides you through some of the basics of testing bots. This workshop demonstrates how you can perform functional testing (using Direct Line).

**cumming soon**

### Time to complete: 45 min